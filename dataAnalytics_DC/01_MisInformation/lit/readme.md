Please add all pdfs or reference information to this directory for your project.

#### First Peer-Reviewed paper
_A Computational Analysis of News Media Bias: A South African Case Study_ by Laurenz A Cornelissen

###### Abstract
News media in South Africa is assumed to be unbiased and objective in their reporting of the news. Indeed, editors are required to uphold an objective and balanced view with no favour to external political or corporate interests. This assumption of objectivity is tested on a large scale by computationally analysing 30 000 articles published by five media houses: News24, SABC, EWN, ENCA, and IOL. Using topic modelling, 38 topics are extracted from the corpus, and sentiment is computed for each topic. The study highlights various cases of both over and under-reporting by media houses on particular topics. We also identify various tonality biases by media houses.

###### Keywords
news, media bias, NLP, topic modelling, south-african politics

###### Reference:
Cornelissen, Laurenz A., et al. "A Computational Analysis of News Media Bias: A South African Case Study." Proceedings of the South African Institute of Computer Scientists and Information Technologists 2019. 2019. 1-10.

###### Notes:
This paper particularly focuses on the different computational methods, and is a bit long, used to extract topics and analyze sentiments from articles of specific media houses, which would then help classify and tag the articles to show the major theme they pertain to. The South-African population is generally opposed to any media that is partisan, and the media is strongly "regarded with distrust." Therefore, any news articles that show allegiance to a specific ideology or political party, particularly ones that align with the current government's party contribute to the distrust of the government. They used R-heavy data collection techniques to clean their data as well as perform sentiment analysis and topic extraction, but particularly for topic modeling. This article may be too advanced for a class lab project.

###### Quote:
 __



#### Second Peer-Reviewed paper
_Dissemination of Misinformative and Biased Information about Prostate Cancer on YouTube_ by Stacy Loeb

###### Abstract
YouTube is a social media platform with more than 1 billion users and >600 000 videos about prostate cancer. Two small studies examined the quality of prostate cancer videos on YouTube, but did not use validated instruments, examine user interactions, or characterize the spread of misinformation. We performed the largest, most comprehensive examination of prostate cancer information on YouTube to date, including the first 150 videos on screening and treatment. We used the validated DISCERN quality criteria for consumer health information and the Patient Education Materials Assessment Tool, and compared results for user engagement. The videos in our sample had up to 1.3 million views (average 45 223) and the overall quality of information was moderate. More videos described benefits (75%) than harms (53%), and only 50% promoted shared decision-making as recommended in current guidelines. Only 54% of the videos defined medical terms and few provided summaries or references. There was a significant negative correlation between scientific quality and viewer engagement (views/month p = 0.004; thumbs up/views p = 0.015). The comments section underneath some videos contained advertising and peer-to-peer medical advice. A total of 115 videos (77%) contained potentially misinformative and/or biased content within the video or comments section, with a total reach of >6 million viewers.

###### Keywords
YouTube, Prostate cancer, Social media, Dissemination, Misinformation

###### Reference:
Loeb, Stacy, et al. "Dissemination of misinformative and biased information about prostate cancer on YouTube." European urology 75.4 (2019): 564-567.

###### Notes:
The aim of the study was not to figure out the extent to which the youtube audience receives biased information about prostate cancer, but "to perform a comprehensive study of YouTube videos on PCa that included validated instruments for content evaluation and comparisons between quality and user popularity and dissemination." They scored videos using the DISCERN quality criteria for consumer health information, as well as study-specific constructs such as including intended audience, favoring new technology, recommending complementary/alternative medicine, commercial bias, and extent of misinformation (not too deeply). They found that very few videos summarized information, provided sources, or discussed multiple options, and only about 50% defined medical terms, divided information into sections, or addressed users directly when describing actions. They conclude that "many popular videos about PCa on YouTube lack key elements of shared decision-making and contain biased content." I find it worrying to note how quickly misinformation was expanded upon after being disseminated. This would be a good article to read for a class lab, however it does lack the data-intensiveness of the example article.

##### Quotes:
_A study of 51 YouTube videos performed in 2008 reported that 73% had fair to poor information content and 69% were biased towards screening or treatment [4]. The authors concluded that YouTube is an inadequate source of PCa information. Since then, there has been a more than 1000-fold increase in YouTube videos about PCa [6] but there are limited data on the nature and quality of current information."_



#### Third Peer-Reviewed paper
_Big data: A big mistake?_ by Tim Harford

###### Abstract
Economist, journalist and broadcaster Tim Harford delivered the 2014 Significance lecture at the Royal Statistical Society International Conference. In this article, republished from the Financial Times , Harford warns us not to forget the statistical lessons of the past as we rush to embrace the big data future.

###### Reference:
Harford, Tim. "Big data: A big mistake?." Significance 11.5 (2014): 14-19.

###### Notes:
Google Flu Trends was originally a highly accurate data-based service, but their predictions became overstated as _Google's engineers weren't trying to figure out what caused what. They were merely finding statistical patterns in the data. They cared about correlation rather than causation_. A lesson this speaker notes is that the size of databases is something we seem to awe at, rather than understanding the many unique and minuscule challenges it may present, the two most prevalent ones being sample error and sample bias. The question that continually arises with biased information is 'who and what is missing from this dataset'? This article would be good to read for a class lab, but lacks the first person perspective of a computer scientist, rather it is a scholar from the economics field discussing the human aspect of data analysis, bias.

###### Quote:
_“There are a lot of small data problems that occur in big data,” says Spiegelhalter. “They don't disappear because you've got lots of the stuff. They get worse.”_



#### Fourth Peer-Reviewed paper
_Don’t forget people in the use of big data for development_ by Joshua Blumenstock

##### Abstract
Today, 95% of the global population has mobile-phone coverage, and the number of people who own a phone is rising fast (see ‘Dialling up’)1. Phones generate troves of personal data on billions of people, including those who live on a few dollars a day. So aid organizations, researchers and private companies are looking at ways in which this ‘data revolution’ could transform international development.

Some businesses are starting to make their data and tools available to those trying to solve humanitarian problems. The Earth-imaging company Planet in San Francisco, California, for example, makes its high-resolution satellite pictures freely available after natural disasters so that researchers and aid organizations can coordinate relief efforts. Meanwhile, organizations such as the World Bank and the United Nations are recruiting teams of data scientists to apply their skills in statistics and machine learning to challenges in international development.

But in the rush to find technological solutions to complex global problems there’s a danger of researchers and others being distracted by the technology and losing track of the key hardships and constraints that are unique to each local context. Designing data-enabled applications that work in the real world will require a slower approach that pays much more attention to the people behind the numbers.
